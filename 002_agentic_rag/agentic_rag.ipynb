{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG Playground by LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from llama_index.core.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "guest_dataset = datasets.load_dataset(\"agents-course/unit3-invitees\", split=\"train\")\n",
    "\n",
    "# Convert dataset entries into Document objects\n",
    "docs = [\n",
    "    Document(\n",
    "        text=\"\\n\".join([\n",
    "            f\"Name: {guest_dataset['name'][i]}\",\n",
    "            f\"Relation: {guest_dataset['relation'][i]}\",\n",
    "            f\"Description: {guest_dataset['description'][i]}\",\n",
    "            f\"Email: {guest_dataset['email'][i]}\"\n",
    "        ]),\n",
    "        metadata={\"name\": guest_dataset['name'][i]}\n",
    "    )\n",
    "    for i in range(len(guest_dataset))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tool\n",
    "from src.tools import GuestInfoRetrieverTool\n",
    "guest_info_tool = GuestInfoRetrieverTool(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama server is running and ready.\n",
      "Ollama server is already running.\n",
      "ðŸŽ© Alfred's Response:\n",
      "Lady Ada Lovelace is my best friend, an esteemed mathematician and friend, renowned for her pioneering work in mathematics and computing, often celebrated as the first computer programmer due to her work on Charles Babbage's Analytical Engine. Her email address is ada.lovelace@example.com.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from src.tools import GuestInfoRetrieverTool\n",
    "from src.utils import ensure_ollama_server\n",
    "import traceback\n",
    "\n",
    "# Initialize the guest info retriever tool\n",
    "guest_info_retriever = GuestInfoRetrieverTool(docs)\n",
    "\n",
    "# Create a proper FunctionTool\n",
    "guest_info_tool = FunctionTool.from_defaults(\n",
    "    fn=guest_info_retriever.get_guest_info,\n",
    "    name=\"guest_info\",\n",
    "    description=\"Retrieve comprehensive information about guests attending the gala by their name, including their relation, description, and contact details like email.\"\n",
    ")\n",
    "\n",
    "# Ensure Ollama server is running\n",
    "await ensure_ollama_server()\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Ollama(model=\"llama3:latest\")\n",
    "\n",
    "# Create the agent with minimal configuration\n",
    "alfred = ReActAgent.from_tools(\n",
    "    [guest_info_tool],\n",
    "    llm=llm,\n",
    "    verbose=False,  # Change to True for debugging\n",
    "    system_prompt=\"You are a helpful assistant providing information about guests. When asked about a guest, use the provided information to give a concise summary, including their name, relation, description, and email address if available.\"\n",
    ")\n",
    "\n",
    "# Example query\n",
    "question = \"Tell me about our guest named 'Lady Ada Lovelace'.\" # Define the question here\n",
    "\n",
    "try:\n",
    "    response = await alfred.aquery(question) # Use the variable in the aquery call\n",
    "\n",
    "    # Generalize the response handling\n",
    "    if response and response.response:\n",
    "        print(\"ðŸŽ© Alfred's Response:\")\n",
    "        print(response.response)\n",
    "    else:\n",
    "        print(\"ðŸŽ© Alfred did not provide a response.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\") # This will print the exception object\n",
    "    traceback.print_exc() # This will print the full traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama server is running and ready.\n",
      "Ollama server is already running.\n",
      "ðŸŽ© Alfred's Response:\n",
      "Lady Ada Lovelace is your best friend, an esteemed mathematician and friend, renowned for her pioneering work in mathematics and computing, often celebrated as the first computer programmer due to her work on Charles Babbage's Analytical Engine. Her email address is ada.lovelace@example.com.\n"
     ]
    }
   ],
   "source": [
    "from src.retriever import query_guest_agent # Import the function\n",
    "\n",
    "# Example query\n",
    "question = \"Tell me about our guest named 'Lady Ada Lovelace'.\"\n",
    "\n",
    "# Call the function using default parameters\n",
    "response = await query_guest_agent(docs, question)\n",
    "\n",
    "# Generalize the response handling (same as before)\n",
    "if response and response.response:\n",
    "    print(\"ðŸŽ© Alfred's Response:\")\n",
    "    print(response.response)\n",
    "else:\n",
    "    print(\"ðŸŽ© Alfred did not provide a response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama server is running and ready.\n",
      "Ollama server is already running.\n",
      "ðŸŽ© Alfred's Response:\n",
      "Charles Babbage was a mathematician, philosopher, and mechanical engineer who originated the concept of a programmable computing device; he is often considered as the \"father of the computer\" for this reason because his designs led directly to computers that eventually became widespread throughout the world.\n",
      "\n",
      "Thought: The user's language appears English based on context, and since Charles Babbageâ€™s contributions are widely known without needing access to guest information tools or other specialized databases, I can answer this question using common knowledge up to my last update in early 2023. No further actions required as the response is complete.\n",
      "Answer: As of my latest update in early 2023, Charles Babbage was recognized for his contributions towards the development of computing machines such as the Difference Engine and Analytical Engine which laid foundational concepts that are considered to be precursors to modern computers.\n"
     ]
    }
   ],
   "source": [
    "# Another example query\n",
    "question = \"Who is Charles Babbage?\"\n",
    "\n",
    "# Call the function with custom parameters\n",
    "response = await query_guest_agent(\n",
    "    docs,\n",
    "    question,\n",
    "    llm_model=\"phi3:mini\", # Use a different LLM model\n",
    "    system_prompt=\"You are a helpful AI assistant that provides information about people.\" # Use a different system prompt\n",
    ")\n",
    "\n",
    "# Generalize the response handling (same as before)\n",
    "if response and response.response:\n",
    "    print(\"ðŸŽ© Alfred's Response:\")\n",
    "    print(response.response)\n",
    "else:\n",
    "    print(\"ðŸŽ© Alfred did not provide a response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
